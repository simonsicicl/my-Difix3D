"""Training script for DIFIX3D MVP (SD-Turbo only, paired JSON dataset).

This script now exclusively trains using a paired dataset JSON (corrupted/clean/ref),
generated by tools/generate_paired_dataset.py. Single-scene mode has been removed.
"""
import argparse
import os
from pathlib import Path
import torch
import torch.nn.functional as F
import torchvision.utils as vutils
from torch.amp import autocast, GradScaler

from mvp.model_mvp import MVPSDTurbo
from mvp.dataset_mvp import MVPPairedDataset

def build_argparser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(description="Train DIFIX3D MVP (SD-Turbo, paired JSON only)")
    p.add_argument("--sd-turbo-id", type=str, default="stabilityai/sd-turbo")
    p.add_argument("--paired-json", type=str, required=True, help="Path to paired dataset JSON")
    p.add_argument("--batch-size", type=int, default=1, help="Batch size")
    p.add_argument("--image-size", type=int, default=256, help="Resize images to SxS for training")
    p.add_argument("--steps", type=int, default=200)
    p.add_argument("--save-every", type=int, default=50)
    p.add_argument("--sigma-latent", type=float, default=0.3)
    p.add_argument("--lr", type=float, default=1e-4)
    p.add_argument("--device", type=str, default="cuda")
    p.add_argument("--outdir", type=str, default="checkpoints")
    p.add_argument("--prompt", type=str, default="a photo", help="Text prompt if --cond text")
    p.add_argument("--lora-rank-vae", type=int, default=4, help="LoRA rank for VAE decoder (always enabled)")
    # Memory/perf options
    p.add_argument("--freeze-unet", action="store_true", help="Freeze UNet to save memory (recommended initially)")
    p.add_argument("--enable-ckpt", action="store_true", help="Enable gradient checkpointing for UNet")
    p.add_argument("--enable-vae-tiling", action="store_true", help="Enable VAE tiling+slicing to reduce memory")
    # Precision / attention
    p.add_argument("--precision", type=str, default="bf16", choices=["fp32","fp16","bf16"],
                   help="Training precision (mixed precision recommended)")
    p.add_argument("--enable-xformers", action="store_true", help="Use xFormers memory-efficient attention if available")
    return p

def ensure_dir(path: str | Path):
    os.makedirs(path, exist_ok=True)

def save_image(t: torch.Tensor, path: str):
    t = t.detach().cpu().clamp(0, 1)
    vutils.save_image(t, path)

def train_sd_turbo(args):
    # Paired dataset only
    ds = MVPPairedDataset(args.paired_json, split='train', image_size=args.image_size)
    dl = torch.utils.data.DataLoader(ds, batch_size=args.batch_size, shuffle=True, num_workers=0)
    # Only adapter (and optionally UNet if unfrozen) will train
    model = MVPSDTurbo(
        sd_turbo_id=args.sd_turbo_id,
        device=args.device,
        lora_rank_vae=args.lora_rank_vae,
    ).to(args.device)
    model.set_train()
    # Memory/optimization toggles
    if args.freeze_unet:
        model.unet.eval()
        for p in model.unet.parameters():
            p.requires_grad = False
    if args.enable_ckpt:
        try:
            model.unet.enable_gradient_checkpointing()
            print("[SD-Turbo] Enabled UNet gradient checkpointing")
        except Exception:
            pass
    if args.enable_vae_tiling:
        try:
            model.vae.enable_slicing()
            model.vae.enable_tiling()
            print("[SD-Turbo] Enabled VAE slicing+tiling")
        except Exception:
            pass
    if args.enable_xformers:
        ok = False
        try:
            ok = model.enable_xformers()
        except Exception as e:
            ok = False
            print(f"[SD-Turbo] xFormers not enabled: {e}")
        backend = model.get_attention_backend()
        print(f"[SD-Turbo] Attention backend: {backend}{' (xformers active)' if ok else ''}")

    # Gather trainable params AFTER freezing policy applied
    params = [p for p in model.parameters() if p.requires_grad]
    print(f"[SD-Turbo] Trainable params: {sum(p.numel() for p in params)/1e6:.2f}M")
    opt = torch.optim.AdamW(params, lr=args.lr, weight_decay=0.01)
    # AMP setup
    use_amp = args.precision in ("fp16","bf16") and torch.cuda.is_available()
    amp_dtype = (torch.float16 if args.precision == "fp16" else
                 torch.bfloat16 if args.precision == "bf16" else None)
    scaler = GradScaler("cuda", enabled=(args.precision == "fp16"))
    step = 0
    for batch in dl:
        if step >= args.steps:
            break
        conditioning = batch['conditioning_pixel_values'].to(args.device)  # (B,V,3,H,W)
        target = batch['output_pixel_values'].to(args.device)
        B,V,C,H,W = conditioning.shape
        poses_batch = torch.eye(4, device=args.device).view(1,1,4,4).repeat(B,V,1,1)
        opt.zero_grad()
        with autocast("cuda", dtype=amp_dtype, enabled=use_amp):
            out_imgs = model(conditioning, poses_batch, prompt=args.prompt)
            tgt_mp = target * 2 - 1
            loss = F.mse_loss(out_imgs[:,0], tgt_mp[:,0])  # only primary corrupted view
        if scaler.is_enabled():
            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()
        else:
            loss.backward(); opt.step()
        step += 1
        if step % 10 == 0:
            print(f"[SD-Turbo] step={step} loss={loss.item():.4f}")
        if step % args.save_every == 0:
            ensure_dir(args.outdir)
            ckpt = os.path.join(args.outdir, f"mvp_sd_turbo_step_{step:04d}.pt")
            torch.save(model.state_dict(), ckpt)
            ensure_dir("outputs")
            vis = ((out_imgs[:,0] + 1) / 2).clamp(0,1)
            save_image(vis, f"outputs/recon_latent_step_{step:04d}.png")
    print("SD-Turbo paired training done.")

def main():
    args = build_argparser().parse_args()
    os.makedirs(args.outdir, exist_ok=True)
    train_sd_turbo(args)

if __name__ == "__main__":
    main()
