"""Paired dataset implementation for DIFIX3D MVP.

This module now exclusively supports paired JSON datasets (corrupted/clean/ref),
generated by tools/generate_paired_dataset.py, and removes single-scene loaders.
"""
from __future__ import annotations

from typing import Dict, Any, List, Optional
from pathlib import Path
import torch
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms.functional as TF
import torchvision.transforms as T

# NOTE: MVPSceneDataset and artifact generation helpers have been removed.


class MVPPairedDataset(Dataset):
    """Load paired corrupted/clean/ref images from a JSON (generated by tools/generate_paired_dataset.py).

    Each entry in JSON split dict contains:
      - image: path to corrupted input (will become conditioning_pixel_values[0])
      - target_image: path to clean target (output_pixel_values[0])
      - ref_image (optional): extra clean reference view stacked as second slice
      - prompt: text caption

    __getitem__ returns dict:
      conditioning_pixel_values: Tensor(V,3,H,W)
      output_pixel_values: Tensor(V,3,H,W) (target stacked with ref if present)
      caption: str

    V = 1 if no ref_image else 2.
    """
    def __init__(self, json_path: str, split: str = "train", image_size: int = 256, tokenizer: Optional[Any] = None):
        import json
        self.json_path = json_path
        with open(json_path, 'r') as f:
            data = json.load(f)
        assert split in data, f"Split {split} not found in {json_path}"
        self.entries = data[split]
        self.keys = list(self.entries.keys())
        self.image_size = image_size
        self.tokenizer = tokenizer
        # transform
        if image_size > 0:
            self.tfm = T.Compose([
                T.Resize((image_size, image_size), interpolation=T.InterpolationMode.BILINEAR),
                T.ToTensor(),
            ])
        else:
            self.tfm = T.ToTensor()

    def __len__(self):
        return len(self.keys)

    def _load_img(self, path: str) -> torch.Tensor:
        with Image.open(path) as im:
            im = im.convert("RGB")
            return self.tfm(im)

    def __getitem__(self, idx: int) -> Dict[str, Any]:
        k = self.keys[idx]
        rec = self.entries[k]
        cond = self._load_img(rec['image'])          # corrupted input
        tgt = self._load_img(rec['target_image'])    # clean target
        if 'ref_image' in rec and rec['ref_image']:
            ref = self._load_img(rec['ref_image'])
            conditioning = torch.stack([cond, ref], dim=0)
            output = torch.stack([tgt, ref], dim=0)
        else:
            conditioning = cond.unsqueeze(0)
            output = tgt.unsqueeze(0)
        out: Dict[str, Any] = {
            'conditioning_pixel_values': conditioning,
            'output_pixel_values': output,
            'caption': rec.get('prompt', 'a photo'),
            'sample_id': k,
        }
        if self.tokenizer is not None:
            input_ids = self.tokenizer(
                out['caption'], max_length=self.tokenizer.model_max_length,
                padding='max_length', truncation=True, return_tensors='pt'
            ).input_ids
            out['input_ids'] = input_ids
        return out

__all__ = ['MVPPairedDataset']